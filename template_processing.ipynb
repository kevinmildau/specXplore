{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template code structure for the pre-processing steps to be done by the end user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_data = \"your-spectral-dataset-filepath.mgf\"\n",
    "filename_standards = \"your-reference-standards-filepath.mgf\"\n",
    "filename_spec2vec1 = \"spec2vec-model-filepath-1\" # trained model\n",
    "filename_spec2vec1 = \"spec2vec-model-filepath-2\" # ???\n",
    "filename_spec2vec1 = \"spec2vec-model-filepath-3\" # ???\n",
    "filename_ms2deepsc = \"ms2deepscore-model-filepath\"\n",
    "path_ms2query = \"ms2query-downloaded-files-folder-path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from specxplore import processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and Annotate spectrum data\n",
    "\n",
    "- An mgf file is loaded and matchms spectrum cleaning and harmonization functions are applied as a pipeline. \n",
    "- ms2query is run to generate classification tables and analog predictions. \n",
    "- The spectrum metadata is extracted as a pandas df.\n",
    "\n",
    "Returns:\n",
    "cleaned spectrum list, classification table, analog table, metadata table. All linked together through sample_idx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = matchms.load_from_mgf # standard matchms loader\n",
    "spectra = clean_spectra() # custom pipeline; metadata cleaning, etc.\n",
    "# --> get idx\n",
    "classification_table, analog_table = run_ms2query + fetch_results # add print for results.csv location\n",
    "metadata_table = fetch_metadata() # any custom addons should be introduced here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and Annotate reference standards\n",
    "\n",
    "- An mgf file is loaded and matchms spectrum cleaning and harmonization functions are applied as a pipeline. \n",
    "- GNPS API interfacing code is used to run classyfire and npclassifier on inchi/smiles.\n",
    "- The spectrum metadata is extracted as a pandas df.\n",
    "- Any additonal spectrum metadata is added if available.\n",
    "- All spectra are indexed by their standards_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standards = matchms.load_from_mgf\n",
    "standards = clean_spectra()\n",
    "classification_table = run_classification() # try_catch based\n",
    "metadata_table = fetch_metadata() # any custom addons should be introduced here.\n",
    "# e.g. is_standard = TRUE column \n",
    "metadata_table[\"is_standard\"] = True # automatically repeats in df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge spectral data\n",
    "\n",
    "Sample data and reference standard data are combined together. Reference standards can be identified easily in post via their is_standard == True entry in the joint metadata table or via their inchi/smiles.\n",
    "\n",
    "A new idx is generated to uniquely identify each spectrum in the merged data. Any otherwise useful spectrum ids will be within the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_tables() # possibly little overlap in columns, lots of NA information for metadata\n",
    "merge_spectra()\n",
    "get_idx() # for merged data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Pairwise Similarities using matchms\n",
    "\n",
    "Requires: model files and their paths, spectrum list\n",
    "Returns: idx ordered pairwise similarities in np matrix format\n",
    "\n",
    "Note:\n",
    "- spec2vec and ms2deepscore come with their own tutorials on how to do this. \n",
    "- installations of both tools may be tricky depdending on the operating system\n",
    "- matchms has a nice interface for this already; all we can do is wrap it away and limit it\n",
    "- WARNING: all three similarity matrices are currently necessary for the dashboard; they cannot be missing.\n",
    "\n",
    "Proposed Solution:\n",
    "\n",
    "--> leave these steps in the original functions style and mainly provide output glue.\n",
    "--> a wrapper function will add additional baggage and will only be handy if we can guarantee it'll run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_ms2deepscore = get_pairwise_similarities(\n",
    "    merged_spectra, \"ms2deepscore\")\n",
    "sm_modified_cosine = get_pairwise_similarities(\n",
    "    merged_spectra, \"modified_cosine\")\n",
    "sm_spec2vec = get_pairwise_similarities(\n",
    "    merged_spectra, \"spec2vec\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run K-Medoid Clustering Grid\n",
    "\n",
    "Here, K-Medoid clustering is run for many levels of K to achieve a good Silhouette score.\n",
    "\n",
    "Idea: this particular code can be run and rerun easily; the grid can be modified until a suitable K is found.\n",
    "\n",
    "Return: A classification table with suitable K clustering coefficients. Small K for broad trends, large K for granularity in the t-SNE embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_grid = [5,10,15...]\n",
    "run_k_medoid_grid()\n",
    "plot(scores)\n",
    "construct_clustering_table # with desired clustering levels "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run t-SNE Grid\n",
    "\n",
    "Here, a t-SNE tuning round is done to assess what levels of perplexity would lead to good distance preservation properties of the embedding. Learning rate and number of iterations may also be investigated, but this tuning will be slower.\n",
    "\n",
    "Speed depends on data size and settings. A single run may take a couple of minutes for large datasets and certain settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities = [...]\n",
    "learning_rates = [...]\n",
    "iterations = [...]\n",
    "run_tsne_grid()\n",
    "plot(scores)\n",
    "\n",
    "construct_tsne_xy()# for selected settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct specXplore data structure\n",
    "\n",
    "Construct a specXplore data structure for use within the dashboard. Essentially a class with named data entries to use. This avoids passing around many parameters at each step of the dashboard, and provides a single place to look at the data structure used throughout specXplore."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "specxplore38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.15 (default, Nov 24 2022, 08:57:44) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91721ca190d4fa69ddf052d455b156e9c3c2fc833760821d49aef838e9e6470e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
